import re
import requests
import json
import time
import os
import pytz
from datetime import datetime
import csv
import io

# ğŸ“Œ ì„¤ì •ê°’
SQL_FILE_PATH = "./faker_07.sql"  # SQL íŒŒì¼ ê²½ë¡œ
BATCH_SIZE = 500  # í•œ ë²ˆì— ë³´ë‚¼ ë ˆì½”ë“œ ê°œìˆ˜ (ì¡°ì ˆ ê°€ëŠ¥)
GRAPHQL_ENDPOINT = "https://jumo-vs8e.onrender.com/graphql"
ADMIN_CREDENTIALS = {
    "username": "admin",
    "password": "1234"
}
# PROGRESS_FILE = "uploaded_count.txt"  # ì‚­ì œ: íŒŒì¼ë³„ë¡œ ê´€ë¦¬í•˜ë„ë¡ ë³€ê²½

# ğŸ“Œ ì»¬ëŸ¼ í‚¤ ì´ë¦„ (JSON ë°ì´í„° ê¸°ì¤€) - ì°¸ê³ ìš© (ì§ì ‘ ì‚¬ìš© X)
# PHONE_KEY = "phoneNumber"
# MEMO_KEY = "Memo"
# COMPANY_INFO_KEY = "CompanyInfo"
# UPDATED_DATE_KEY = "UpdatedDate"
# ACTION_TYPE_KEY = "ActionType"

# ğŸ“Œ userType ë§¤í•‘
# USER_TYPE_MAPPING = {
#     256: "ì˜¤í”¼",
#     257: "1ì¸ìƒµ",
#     258: "íœ´ê²Œí…”",
#     260: "í‚¤ìŠ¤ë°©",
#     261: "ì•„ë¡œë§ˆ",
#     262: "ì¶œì¥",
#     263: "1ì¸ìƒµ",
#     264: "ì•„ë¡œë§ˆ",
#     265: "ìŠ¤ë§ˆ",
#     266: "ì˜¤í”¼",
#     267: "ë…¸ë˜ë°©",
#     268: "í‚¤ìŠ¤ë°©"
# }

### 1ï¸âƒ£ ë¡œê·¸ì¸í•´ì„œ í† í° ë°›ì•„ì˜¤ê¸° ###
def get_access_token():
    login_query = {
        "query": """ 
        mutation AdminLogin($username: String!, $password: String!) {
          adminLogin(username: $username, password: $password) {
            accessToken
          }
        }
        """,
        "variables": ADMIN_CREDENTIALS
    }

    try:
        response = requests.post(GRAPHQL_ENDPOINT, json=login_query, timeout=10) # íƒ€ì„ì•„ì›ƒ ì¶”ê°€
        response.raise_for_status() # 200 ì™¸ ìƒíƒœì½”ë“œì— ëŒ€í•´ ì˜ˆì™¸ ë°œìƒ
    except requests.exceptions.RequestException as e:
        print(f"âŒ ë¡œê·¸ì¸ ìš”ì²­ ì‹¤íŒ¨ (ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜): {e}")
        return None
    except Exception as e:
        print(f"âŒ ë¡œê·¸ì¸ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return None


    if response.status_code != 200:
        print(f"âŒ ë¡œê·¸ì¸ ìš”ì²­ ì‹¤íŒ¨ (HTTP {response.status_code}): {response.text}")
        return None

    try:
        data = response.json()
    except json.JSONDecodeError:
        print(f"âŒ ë¡œê·¸ì¸ ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {response.text}")
        return None

    if "errors" in data:
        print(f"âŒ GraphQL ì˜¤ë¥˜: {data['errors']}")
        return None

    try:
        return data["data"]["adminLogin"]["accessToken"]
    except (KeyError, TypeError):
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ í˜•ì‹: {data}")
        return None

### 2ï¸âƒ£ SQL íŒŒì¼ íŒŒì‹±í•´ì„œ ë°ì´í„° ë³€í™˜ ###
def parse_sql_file(sql_file_path):
    records = []
    # ì œì™¸ ì¹´ìš´í„° ì´ˆê¸°í™”
    dropped_by_missing_data = 0 # í•„ìˆ˜ ë°ì´í„° ë¶€ì¡±/í˜•ì‹ ì˜¤ë¥˜ í†µí•©
    dropped_by_phone_format = 0
    dropped_by_all_empty = 0
    processed_records = 0
    initial_row_count = 0 # ì‹¤ì œ ë°ì´í„° í–‰ ìˆ˜
    parsing_error_details = []

    sql_base_name = os.path.splitext(os.path.basename(sql_file_path))[0]
    useless_log_path = f"{sql_base_name}_useless.txt"
    error_log_path = f"{sql_base_name}_parsing_errors.log"

    try:
        with open(sql_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
            # ëª¨ë“  VALUES ê·¸ë£¹ì„ ì°¾ìŠµë‹ˆë‹¤
            values_pattern = r"\(([\d]+,\s*'[^']*',\s*'[^']*',\s*'[^']*',\s*'[^']*',\s*'[^']*',\s*'[^']*',\s*'[^']*',\s*'[^']*',\s*'[^']*')\)"
            matches = re.finditer(values_pattern, content)
            
            for match in matches:
                initial_row_count += 1
                try:
                    # ê°’ë“¤ì„ íŒŒì‹±í•©ë‹ˆë‹¤
                    values_str = match.group(1)
                    values = re.findall(r"'([^']*)'|(\d+)", values_str)
                    values = [v[0] if v[0] else v[1] for v in values]
                    
                    if len(values) < 10:  # contact í…Œì´ë¸”ì˜ ëª¨ë“  í•„ë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                        dropped_by_missing_data += 1
                        error_info = {"line_num": initial_row_count, "original_row": values, "error_message": "í•„ë“œ ê°œìˆ˜ ë¶€ì¡±"}
                        parsing_error_details.append(error_info)
                        continue

                    # ë°ì´í„° ì¶”ì¶œ
                    phone_number = values[3].strip()  # phoneNumber í•„ë“œ
                    memo = values[4].strip()         # Memo í•„ë“œ
                    company_info = values[6].strip() # CompanyInfo í•„ë“œ
                    updated_date_str = values[7].strip() # UpdatedDate í•„ë“œ

                    # ì „í™”ë²ˆí˜¸ ì „ì²˜ë¦¬ ë° ê²€ì¦
                    phone_number = phone_number.strip('#')
                    phone_number = phone_number.strip("'")
                    if phone_number.startswith('*77'):
                        phone_number = phone_number[3:]
                    elif phone_number.startswith('*281'):
                        phone_number = phone_number[4:]
                    
                    if phone_number.startswith('+82'):
                        phone_number = '0' + phone_number[3:]
                    
                    if phone_number.startswith('10') and len(phone_number) == 10:
                        phone_number = '0' + phone_number

                    # ì „í™”ë²ˆí˜¸ íŒ¨í„´ ê²€ì‚¬
                    is_valid = False
                    if re.match(r'^01([0|1|6|7|8|9])-?([0-9]{3,4})-?([0-9]{4})$', phone_number):
                        is_valid = True
                    elif re.match(r'^(051|055|054|02|070)-?([0-9]{3,4})-?([0-9]{4})$', phone_number):
                        is_valid = True
                    elif re.match(r'^(1588|1544|1688|1644)-?([0-9]{4})$', phone_number):
                        is_valid = True

                    if not is_valid:
                        dropped_by_phone_format += 1
                        continue
                        
                    if not phone_number or phone_number == "-1":
                        dropped_by_missing_data += 1
                        continue

                    # CompanyInfoì—ì„œ ìœ ì €íƒ€ì…ê³¼ ìœ ì €ë„¤ì„ ì¶”ì¶œ
                    company_parts = company_info.split()
                    if len(company_parts) > 1:
                        user_type = company_parts[-1]  # ë§ˆì§€ë§‰ ë‹¨ì–´ë¥¼ ìœ ì €íƒ€ì…ìœ¼ë¡œ
                        user_name = company_info  # CompanyInfo ì „ì²´ë¥¼ userNameìœ¼ë¡œ
                    else:
                        user_type = company_info  # í•œ ë‹¨ì–´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        user_name = company_info

                    # ì‹œê°„ ì²˜ë¦¬
                    created_at = "2020-01-01T00:00:00+00:00"  # ê¸°ë³¸ê°’
                    try:
                        parsed_time = datetime.strptime(updated_date_str, '%Y-%m-%d %H:%M:%S')
                        if parsed_time:
                            kst = pytz.timezone('Asia/Seoul')
                            utc = pytz.UTC
                            if parsed_time.tzinfo is None:
                                kst_time = kst.localize(parsed_time)
                            else:
                                kst_time = parsed_time
                            utc_time = kst_time.astimezone(utc)
                            created_at = utc_time.isoformat()
                    except Exception as e:
                        print(f"âš ï¸ ì‹œê°„ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ (í–‰ {initial_row_count}): {e}")

                    # ìµœì¢… ë ˆì½”ë“œ ìƒì„±
                    final_record = {
                        "name": memo if memo and memo != "-1" else None,  # Memo í•„ë“œ ì „ì²´ë¥¼ nameìœ¼ë¡œ ì‚¬ìš©
                        "phoneNumber": phone_number,
                        "userName": user_name if user_name and user_name != "\\\\N" and user_name != "-1" else None,
                        "userType": user_type,
                        "createdAt": created_at,
                    }

                    # í•„ìˆ˜ í•„ë“œ ìœ íš¨ì„± ê²€ì‚¬
                    required_fields = ["name", "phoneNumber", "userName", "userType"]
                    is_valid = True
                    for field in required_fields:
                        if final_record[field] is None or final_record[field] == "" or final_record[field] == "-1":
                            is_valid = False
                            error_info = {
                                "line_num": initial_row_count,
                                "original_row": values,
                                "error_message": f"í•„ìˆ˜ í•„ë“œ '{field}' ëˆ„ë½ ë˜ëŠ” ìœ íš¨í•˜ì§€ ì•Šì€ ê°’"
                            }
                            parsing_error_details.append(error_info)
                            break
                    
                    if not is_valid:
                        dropped_by_missing_data += 1
                        continue

                    records.append(final_record)
                    processed_records += 1

                except Exception as e:
                    dropped_by_missing_data += 1
                    error_info = {"line_num": initial_row_count, "original_row": values if 'values' in locals() else None, 
                                "error_message": f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"}
                    parsing_error_details.append(error_info)
                    continue

    except FileNotFoundError:
        print(f"âŒ SQL íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {sql_file_path}")
        return []
    except Exception as e:
        print(f"âŒ SQL íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        return []

    # íŒŒì‹± ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
    final_record_count = len(records)
    total_dropped = dropped_by_missing_data + dropped_by_phone_format + dropped_by_all_empty

    print(f"ğŸ” SQL íŒŒì‹± ê²°ê³¼ ({sql_file_path}):")
    print(f"  - íŒŒì¼ ë‚´ ì´ ë°ì´í„° í–‰ ìˆ˜: {initial_row_count}")
    print(f"  - ìµœì¢… ë³€í™˜ëœ ë ˆì½”ë“œ ìˆ˜: {final_record_count}")
    print(f"  - --- ì œì™¸ ìƒì„¸ ---")
    print(f"  - ë°ì´í„° ë¶€ì¡±/ì¶”ì¶œ ì˜¤ë¥˜: {dropped_by_missing_data}")
    print(f"  - ì „í™”ë²ˆí˜¸ í˜•ì‹ ì˜¤ë¥˜ë¡œ ì œì™¸: {dropped_by_phone_format}")
    print(f"  - ì£¼ìš” í•„ë“œ(name, userName) ëª¨ë‘ ë¹„ì–´ì„œ ì œì™¸: {dropped_by_all_empty}")
    print(f"  - ì´ ì œì™¸ëœ ë ˆì½”ë“œ ìˆ˜: {total_dropped}")

    # ë¡œê·¸ íŒŒì¼ ì €ì¥
    try:
        with open(useless_log_path, "w", encoding='utf-8') as f:
            f.write(f"SQL íŒŒì‹± ê²°ê³¼ ({sql_file_path}):\n")
            f.write(f"  - íŒŒì¼ ë‚´ ì´ ë°ì´í„° í–‰ ìˆ˜: {initial_row_count}\n")
            f.write(f"  - ìµœì¢… ë³€í™˜ëœ ë ˆì½”ë“œ ìˆ˜: {final_record_count}\n")
            f.write(f"  - --- ì œì™¸ ìƒì„¸ ---\n")
            f.write(f"  - ë°ì´í„° ë¶€ì¡±/ì¶”ì¶œ ì˜¤ë¥˜: {dropped_by_missing_data}\n")
            f.write(f"  - ì „í™”ë²ˆí˜¸ í˜•ì‹ ì˜¤ë¥˜ë¡œ ì œì™¸: {dropped_by_phone_format}\n")
            f.write(f"  - ì£¼ìš” í•„ë“œ(name, userName) ëª¨ë‘ ë¹„ì–´ì„œ ì œì™¸: {dropped_by_all_empty}\n")
            f.write(f"  - ì´ ì œì™¸ëœ ë ˆì½”ë“œ ìˆ˜: {total_dropped}\n\n")
            
            # ì œì™¸ëœ ë°ì´í„° ìƒì„¸ ì •ë³´ ì €ì¥
            f.write("=== ì œì™¸ëœ ë°ì´í„° ìƒì„¸ ì •ë³´ ===\n\n")
            
            # ë°ì´í„° ë¶€ì¡±/ì¶”ì¶œ ì˜¤ë¥˜ ë°ì´í„°
            if parsing_error_details:
                f.write("1. ë°ì´í„° ë¶€ì¡±/ì¶”ì¶œ ì˜¤ë¥˜ ë°ì´í„°:\n")
                for error in parsing_error_details:
                    f.write(f"  - ë¼ì¸ {error['line_num']}: {error['error_message']}\n")
                    f.write(f"    ì›ë³¸ ë°ì´í„°: {error['original_row']}\n\n")
            
            # ì „í™”ë²ˆí˜¸ í˜•ì‹ ì˜¤ë¥˜ ë°ì´í„° ì €ì¥ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
            phone_format_errors = []
            
            # ì£¼ìš” í•„ë“œ ë¹„ì–´ìˆëŠ” ë°ì´í„° ì €ì¥ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
            empty_fields_data = []
            
            # ì›ë³¸ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ì½ì–´ì„œ ì œì™¸ëœ ë°ì´í„° ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
            with open(sql_file_path, 'r', encoding='utf-8') as sql_file:
                content = sql_file.read()
                # INSERT INTO ë¬¸ì¥ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤
                insert_pattern = r"INSERT INTO `contact` \([^)]+\) VALUES\s*\((.*?)\);"
                matches = re.finditer(insert_pattern, content, re.DOTALL)
                
                for line_num, match in enumerate(matches, 1):
                    try:
                        values = re.findall(r"'([^']*)'|(\d+)", match.group(1))
                        values = [v[0] if v[0] else v[1] for v in values]
                        
                        if len(values) < 10:
                            continue
                            
                        phone_number = values[3].strip()  # phoneNumber í•„ë“œ
                        memo = values[4].strip()         # Memo í•„ë“œ
                        company_info = values[6].strip() # CompanyInfo í•„ë“œ
                        
                        # ì „í™”ë²ˆí˜¸ í˜•ì‹ ê²€ì‚¬
                        phone_number = phone_number.strip('#').strip("'")
                        if phone_number.startswith('*77'):
                            phone_number = phone_number[3:]
                        elif phone_number.startswith('*281'):
                            phone_number = phone_number[4:]
                            
                        if phone_number.startswith('+82'):
                            phone_number = '0' + phone_number[3:]
                            
                        if phone_number.startswith('10') and len(phone_number) == 10:
                            phone_number = '0' + phone_number

                        # ì „í™”ë²ˆí˜¸ íŒ¨í„´ ê²€ì‚¬
                        is_valid = False
                        if re.match(r'^01([0|1|6|7|8|9])-?([0-9]{3,4})-?([0-9]{4})$', phone_number):
                            is_valid = True
                        elif re.match(r'^(051|055|054|02|070)-?([0-9]{3,4})-?([0-9]{4})$', phone_number):
                            is_valid = True
                        elif re.match(r'^(1588|1544|1688|1644)-?([0-9]{4})$', phone_number):
                            is_valid = True

                        if not is_valid:
                            phone_format_errors.append({
                                "line_num": line_num,
                                "data": values,
                                "phone": phone_number
                            })
                            continue
                            
                        # ì£¼ìš” í•„ë“œ ë¹„ì–´ìˆëŠ”ì§€ ê²€ì‚¬
                        if all(value is None or value == "" or value == "-1" for value in [memo, company_info]):
                            empty_fields_data.append({
                                "line_num": line_num,
                                "data": values
                            })
                            
                    except Exception:
                        continue
            
            # ì „í™”ë²ˆí˜¸ í˜•ì‹ ì˜¤ë¥˜ ë°ì´í„° ì €ì¥
            if phone_format_errors:
                f.write("\n2. ì „í™”ë²ˆí˜¸ í˜•ì‹ ì˜¤ë¥˜ ë°ì´í„°:\n")
                for error in phone_format_errors:
                    f.write(f"  - ë¼ì¸ {error['line_num']}: ì˜ëª»ëœ ì „í™”ë²ˆí˜¸ í˜•ì‹ ({error['phone']})\n")
                    f.write(f"    ì›ë³¸ ë°ì´í„°: {error['data']}\n\n")
            
            # ì£¼ìš” í•„ë“œ ë¹„ì–´ìˆëŠ” ë°ì´í„° ì €ì¥
            if empty_fields_data:
                f.write("\n3. ì£¼ìš” í•„ë“œ(name, userName) ëª¨ë‘ ë¹„ì–´ìˆëŠ” ë°ì´í„°:\n")
                for data in empty_fields_data:
                    f.write(f"  - ë¼ì¸ {data['line_num']}:\n")
                    f.write(f"    ì›ë³¸ ë°ì´í„°: {data['data']}\n\n")
            
            f.flush()
        print(f"âœ… ì œì™¸ëœ ë°ì´í„° ìƒì„¸ ì •ë³´ê°€ {os.path.abspath(useless_log_path)} ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except IOError as e:
        print(f"âŒ {useless_log_path} íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if parsing_error_details:
        try:
            with open(error_log_path, "w", encoding='utf-8') as f:
                json.dump(parsing_error_details, f, ensure_ascii=False, indent=2)
            print(f"âœ… íŒŒì‹± ì˜¤ë¥˜ ë°ì´í„°ê°€ {os.path.abspath(error_log_path)} ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except IOError as e:
            print(f"âŒ {error_log_path} íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    return records

### 3ï¸âƒ£ ì—…ë¡œë“œëœ ê°œìˆ˜ë¥¼ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ (ì¤‘ê°„ ì¬ì‹œì‘ ê°€ëŠ¥) ###
def save_progress(uploaded_count, base_name):
    progress_file_path = f"{base_name}_uploaded_count.txt"
    try:
        with open(progress_file_path, "w") as f:
            f.write(str(uploaded_count))
    except IOError as e:
        print(f"âŒ ì§„í–‰ ìƒíƒœ íŒŒì¼({progress_file_path}) ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def load_progress(base_name):
    progress_file_path = f"{base_name}_uploaded_count.txt"
    if os.path.exists(progress_file_path):
        try:
            with open(progress_file_path, "r") as f:
                content = f.read().strip()
                if content:
                    return int(content)
                else:
                    print(f"âš ï¸ ì§„í–‰ ìƒíƒœ íŒŒì¼({progress_file_path})ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. 0ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
                    return 0
        except ValueError:
            print(f"âŒ ì§„í–‰ ìƒíƒœ íŒŒì¼({progress_file_path})ì˜ ë‚´ìš©ì„ ìˆ«ìë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 0ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
            return 0
        except IOError as e:
            print(f"âŒ ì§„í–‰ ìƒíƒœ íŒŒì¼({progress_file_path}) ì½ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. 0ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
            return 0
    return 0

### 3.5ï¸âƒ£ ì—…ë¡œë“œ ì˜¤ë¥˜ ë¡œê¹… í•¨ìˆ˜ ###
def log_upload_error(base_name, batch_data, error_response_text, batch_start_index):
    error_log_path = f"{base_name}_upload_errors.log"
    timestamp = datetime.now(pytz.timezone('Asia/Seoul')).isoformat()
    problematic_records = []
    try:
        error_json = json.loads(error_response_text)
        if isinstance(error_json.get('errors'), list):
            for error in error_json['errors']:
                if isinstance(error.get('message'), str):
                    match = re.search(r'records\\\[(\d+)\\\]\.(\w+)', error['message'])
                    if match:
                        try:
                            index_in_batch = int(match.group(1))
                            field_name = match.group(2)
                            if 0 <= index_in_batch < len(batch_data):
                                problematic_records.append({
                                    "index_in_batch": index_in_batch,
                                    "field_name": field_name,
                                    "record_data": batch_data[index_in_batch]
                                })
                        except (ValueError, IndexError): pass
    except json.JSONDecodeError: pass
    error_entry = {
        "timestamp": timestamp,
        "batch_start_index": batch_start_index,
        "error_response_text": error_response_text,
        "identified_problematic_records": problematic_records,
        "full_failed_batch_data": batch_data
    }
    try:
        with open(error_log_path, "a", encoding='utf-8') as f:
            f.write(json.dumps(error_entry, ensure_ascii=False, indent=2) + "\n")
        print(f"ğŸ”´ ì—…ë¡œë“œ ì˜¤ë¥˜ ë°œìƒ: ìƒì„¸ ì •ë³´ê°€ {error_log_path} ì— ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except IOError as e: print(f"âŒ ì—…ë¡œë“œ ì˜¤ë¥˜ ë¡œê·¸ íŒŒì¼({error_log_path}) ì“°ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    except Exception as e: print(f"âŒ ì—…ë¡œë“œ ì˜¤ë¥˜ ë¡œê·¸ ì €ì¥ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")

### 4ï¸âƒ£ ë°ì´í„° ì—…ë¡œë“œ (ë°°ì¹˜ ì²˜ë¦¬ + ì¬ì‹œë„) ###
def upload_records(access_token, records, base_name):
    headers = { "Authorization": f"Bearer {access_token}", "Content-Type": "application/json" }
    mutation_query = { "query": """ 
        mutation UpsertPhoneRecords($records: [PhoneRecordInput!]!) {
          upsertPhoneRecords(records: $records)
        }
        """ }
    total_records = len(records)
    uploaded_count = load_progress(base_name)
    print(f"ğŸ“¤ ì´ {total_records}ê°œì˜ ë ˆì½”ë“œ ì¤‘ {uploaded_count}ê°œê¹Œì§€ ì—…ë¡œë“œë¨. ì´ì–´ì„œ ì§„í–‰.")
    success = False # ìµœì¢… ì„±ê³µ ì—¬ë¶€ í”Œë˜ê·¸

    for i in range(uploaded_count, total_records, BATCH_SIZE):
        batch = records[i:i + BATCH_SIZE]
        mutation_query["variables"] = {"records": batch}
        
        # ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ê²½ìš° ìƒì„¸ ì •ë³´ ì¶œë ¥
        if i == 0:
            print("\nì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ì²« ë²ˆì§¸ ë ˆì½”ë“œ:")
            print(json.dumps(batch[0], ensure_ascii=False, indent=2))
            print("\nì „ì²´ mutation query:")
            print(json.dumps(mutation_query, ensure_ascii=False, indent=2))
            
        retries = 3
        batch_success = False # ë°°ì¹˜ ì„±ê³µ ì—¬ë¶€
        response_text = ""
        while retries > 0:
            try:
                response = requests.post(GRAPHQL_ENDPOINT, json=mutation_query, headers=headers, timeout=30)
                response_text = response.text
                response.raise_for_status()
                response_json = response.json()
                if "errors" in response_json:
                    print(f"âŒ GraphQL ì˜¤ë¥˜ ë°œìƒ: {response_text}")
                    retries -= 1
                    if retries > 0: time.sleep(2)
                    continue
                else:
                     uploaded_count = i + len(batch)
                     save_progress(uploaded_count, base_name)
                     print(f"âœ… {uploaded_count} / {total_records} ê°œ ì™„ë£Œ ({uploaded_count/total_records*100:.2f}%)")
                     batch_success = True
                     success = True # í•œ ë°°ì¹˜ë¼ë„ ì„±ê³µí•˜ë©´ ì „ì²´ ì„±ê³µ í”Œë˜ê·¸ ì—…ë°ì´íŠ¸
                     break
            except requests.exceptions.Timeout:
                print(f"âŒ ìš”ì²­ ì‹œê°„ ì´ˆê³¼ (ì¬ì‹œë„ {4 - retries}/3)"); response_text = "Request Timeout"
                retries -= 1; time.sleep(5)
            except requests.exceptions.RequestException as e:
                print(f"âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ (ì¬ì‹œë„ {4 - retries}/3): {e}"); response_text = str(e)
                retries -= 1; time.sleep(5)
            except json.JSONDecodeError:
                print(f"âŒ ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨ (ì¬ì‹œë„ {4-retries}/3): {response_text}"); retries -= 1; time.sleep(2)
            except Exception as e:
                print(f"âŒ ì—…ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ (ì¬ì‹œë„ {4-retries}/3): {e}"); response_text = str(e)
                retries -= 1; time.sleep(2)

        if not batch_success:
            log_upload_error(base_name, batch, response_text, i)
            print(f"ğŸ”´ ë°°ì¹˜ {i} ~ {i+len(batch)-1} ì—…ë¡œë“œ ìµœì¢… ì‹¤íŒ¨. ë‹¤ìŒ ë°°ì¹˜ë¡œ ì§„í–‰.")
            success = False # í•œ ë°°ì¹˜ë¼ë„ ì‹¤íŒ¨í•˜ë©´ ì „ì²´ ì„±ê³µ í”Œë˜ê·¸ false

    error_log_path = f"{base_name}_upload_errors.log"
    if os.path.exists(error_log_path):
        try:
            with open(error_log_path, 'rb+') as f:
                f.seek(0, os.SEEK_END)
                if f.tell() > 3:
                    f.seek(-3, os.SEEK_END)
                    if f.read(3) == b'\n,\n':
                        f.seek(-3, os.SEEK_END)
                        f.truncate()
                    else:
                         f.seek(-2, os.SEEK_END)
                         if f.read(2) == b',\n':
                              f.seek(-2, os.SEEK_END)
                              f.truncate()
            with open(error_log_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                if content:
                     error_entries_str = '[' + content.rstrip(',') + ']'
                     with open(error_log_path, 'w', encoding='utf-8') as wf:
                          parsed_entries = json.loads(error_entries_str)
                          json.dump(parsed_entries, wf, ensure_ascii=False, indent=2)
                     print(f"â„¹ï¸ ì—…ë¡œë“œ ì˜¤ë¥˜ ë¡œê·¸ íŒŒì¼({error_log_path})ì„ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤.")
                else: print(f"â„¹ï¸ ì—…ë¡œë“œ ì˜¤ë¥˜ ë¡œê·¸ íŒŒì¼({error_log_path})ì´ ë¹„ì–´ìˆì–´ í›„ì²˜ë¦¬ë¥¼ ê±´ë„ˆë‹ˆë‹¤.")
        except Exception as e: print(f"âš ï¸ ì—…ë¡œë“œ ì˜¤ë¥˜ ë¡œê·¸ íŒŒì¼({error_log_path}) í›„ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    print("âœ… ëª¨ë“  ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ!" if success else "âš ï¸ ì—…ë¡œë“œ ì¤‘ ì¼ë¶€ ë°°ì¹˜ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

### ì‹¤í–‰ ###
if __name__ == "__main__":
    print("ğŸ”‘ ë¡œê·¸ì¸ ì¤‘...")
    token = get_access_token()

    if token:
        print(f"ğŸ“‚ SQL íŒŒì¼({SQL_FILE_PATH}) íŒŒì‹± ì¤‘...")
        sql_base_name = os.path.splitext(os.path.basename(SQL_FILE_PATH))[0]
        records = parse_sql_file(SQL_FILE_PATH)

        if records:
            print(f"ğŸ“„ {len(records)}ê°œì˜ ë°ì´í„° ë³€í™˜ ì™„ë£Œ.")
            print("\nâœ¨ ì²« ë²ˆì§¸ ë ˆì½”ë“œ ë¯¸ë¦¬ë³´ê¸°:")
            try:
                print(json.dumps(records[0], indent=2, ensure_ascii=False))
            except Exception as e:
                print(f"ì²« ë²ˆì§¸ ë ˆì½”ë“œ í‘œì‹œì— ì˜¤ë¥˜ ë°œìƒ: {e}")
                print(records[0])

            while True:
                confirm = input("\nâ“ ì—…ë¡œë“œë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower().strip()
                if confirm == 'y':
                    print("ğŸš€ ì—…ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
                    upload_records(token, records, sql_base_name)
                    break
                elif confirm == 'n':
                    print("âœ‹ ì—…ë¡œë“œë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
                    break
                else:
                    print("âš ï¸ 'y' ë˜ëŠ” 'n'ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            print("âŒ ë³€í™˜ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì—…ë¡œë“œë¥¼ ê±´ë„ˆë‹ˆë‹¤.")
    else:
        print("âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
